<main class="page">
    <style>
        .gallery {
        display: grid;
        grid-template-columns: repeat(2, 1fr); /* 2 columns */
        gap: 10px; /* space between images */
        max-width: 600px;
        margin: auto;
        }
        .gallery img {
        width: 100%;
        height: auto;
        border-radius: 6px;
        }
        .line {
        display: grid;
        grid-template-columns: repeat(3, 1fr); /* 3 images per row */
        gap: 12px;
        max-width: 960px;
        margin: 2rem auto;
        }
        .line img {
        width: 100%;
        height: 220px;       /* same height for all */
        object-fit: contain;   /* crop to fill without distortion */
        border-radius: 8px;
        display: block;
        }
    </style>
    <!-- Article header -->
    <h1 class="title"> Fun with Filters and Frequencies </h1>

    <div class="meta">
      <div><strong>Author</strong><div>Abrahm DeVine</div></div>
      <div><strong>Published</strong><div>September 26, 2025</div></div>
    </div>
  
    <!-- Content + Sidebar -->
    <div class="layout">
      <!-- Main content -->
      <article>
        <section id="introduction">
          <h2>Introduction</h2>
          <p class="placeholder">   <b>1.1 </b>Here we explore the affordances of experimenting with images in the Fourier domain, including image sharpening, blending, and splicing.</p>
        </section>
  
        <section id="Part1">
            <h2> Part 1: Filters </h2>
            <p class="placeholder"> Here we implement convolution from scratch between an image and a finite difference filter, first using four for loops and then two.
                The finite difference operator is defined as a change in x and y directions, and is essentially a derivitive. </p>
            
            <img src="data/finitedifference.jpg" alt="The finite difference operators. ">

            <p class="placeholder"> Here we can see the effects of filtering an image of me using a 3x3 box filter (averaging), and each of the finite difference operators. Below
                are two convolution implementations, using both 4 and 2 loops to calculate the convolutions.
            </p>
            
            <figure class="line">
                <img src="data/convolve4l.jpg" alt="Convolution implemented with 4 four loops. ">
                <img src="data/convolve2l.jpg" alt="Convolution implemented with 2 four loops. ">
            </figure>
            
            <figure class="gallery">
                <img src="data/BW_self.jpg" alt="The original image. ">
                <img src="data/BW_self_boxfiltered.jpg" alt="The image after a convolution with a 3x3 box filter. ">
                <img src="data/BW_selfDX.jpg" alt="The image after a convolution with the finite difference filter in the x direction. ">
                <img src="data/BW_selfDY.jpg" alt="The image after a convolution with the finite difference filter in the x direction. ">
            </figure>

        

            <p class="placeholder"> <b>1.2</b> Below we also apply the finite difference operators to camera man image, and take the magnitude of these two convolved images 
                combined to create a gradiant magnitude image, which highlights the greatest changes in the x and y directions (edges). Using a threshold of 45 (determined
                qualitatively), we binarize this image to suppress the noise and highlight the real edges. Below we see the original image, its convolution with the finite difference operator in the x direction, the y direction, and finally the binarized gradiant
                magnitude image.
            </p>

            <figure class="gallery">
                    <img src="data/cameraman.jpg" alt="The original camera man image.">
                    <img src="data/cameraman_dx.jpg" alt="The camera man image after a convolution with the finite difference filter in the x direction. ">
                    <img src="data/cameraman_dy.jpg" alt="The camera man image after a convolution with the finite difference filter in the y direction. ">
                    <img src="data/cameraman_gradmag.jpg" alt="The camera man image after a convolution with the finite difference filter in the y direction. ">
            </figure>

            <p class="placeholder"> <b>1.3</b> Here we introduce an additional convolution with the Gaussian filter to reduce noise. This allows us to reduce the threshold
                when binarizing the image. We can acheive the same result by creating a derivivite of the Gaussian filter and convolving with the camera man image. Below is 
                the original gradiant magnitude image followed by the binarized image at thresholds 10, 25, and 40.
            </p>

            <figure class="gallery">
                <img src="data/cameraman_noT.jpg" alt="The original camera man image.">
                <img src="data/cameraman_Ggradman10.jpg" alt="The camera man image after a convolution with the finite difference filter in the x direction. ">
                <img src="data/cameraman_Ggradman20.jpg" alt="The camera man image after a convolution with the finite difference filter in the y direction. ">
                <img src="data/cameraman_Ggradman40.jpg" alt="The camera man image after a convolution with the finite difference filter in the y direction. ">
            </figure>

            <p>
                   <b>Visualization of gradient orientations in HSV colorspace: </b> Here we visualize the orientations of the gradient with colors on 
                    cyclical color wheel cooresponding to the direction (shown as hue), and the magnitude of the gradient affecting the saturation and value
                    of the pixels. We see that the bottom of the swim cap is roughly yellow while the top right is magenta. In these spots, the large changes in color are vertical and 
                    horizontal, with their colors roughly 90 degrees apart on the color wheel.
            </p>
            <center> <img src="data/hsv.jpg"></center>
        </section>

        <section id="Part 2">
            <h2>Part 2: Frequencies </h2>
          
            <p><b>2.1 Image Sharpening</b>
                By applying a low pass filter to an image and subtracting the result from the original, we are left with only the high frequencies, which can be added
                to the original image to give the illusion of a sharper image. See two examples below with the original image, its high frequencies,
                and to its "sharper" creation.
            </p>

            <figure class="line">
                <img src="data/taj.jpg">
                <img src="data/taj_highfrequencies.jpg">
                <img src="data/taj_tajsharpened.jpg">
            </figure>

            <p>
                We can apply the same transformation to the high quality image below.
            </p>
            
                <figure class="line">
                    <img src = "data/lights.png">
                </figure>

            <p> And below, we see the blurred image, the high freuencies of the image, the "sharpened" image, and finally a version that is blurred and then resharpened.
                Mathematically, this final image is the same as the original.
            </p>

                <figure class="gallery">
                    <img src="data/lights_blur.jpg">
                    <img src="data/lights_hf.jpg">
                    <img src="data/lights_sharp.jpg">
                    <img src="data/lights_bs.jpg">
                </figure>


            <p> <b> 2.2 Hybrid Images </b>
                Using a high pass filter on one image and a low pass on another, we can align the images strategically to create an image that appears different
                from different viewing positions. From up close, the high frequencies dominate while from afar the low frequencies do. Original images are displayed below
                along with the high pass, low pass, and combined versions.

                <figure class="line">
                    <img src="data/trump.jpg">
                    <img src="data/cry.jpg">
                </figure>

                <figure class="line">
                    <img src="data/trump_hf.jpg">
                    <img src="data/baby_blur.jpg">
                    <img src="data/combined.jpg">
                </figure>
            </p>

            <p>
                <b> Fourier Analysis: </b> Below, we consider the original images in the Fourier domain. (Trump on the left, baby on the right)
                
                <figure class="line">
                    <img src="data/trump_f.jpg">
                    <img src="data/baby_f.jpg">
                </figure>

                And below we see their filtered components and the hybrid image in the Fourier domain. (Trump on the left, baby in the middle, hybrid on the right.) 
                We see that the Trump image has few high frequencies with a bright center cooresponding to low frequencies, whereas the baby image shows lots of 
                high frequencies.

                <figure class="line">
                    <img src="data/trump_tf.jpg">
                    <img src="data/baby_tf.jpg">
                    <img src="data/hyrbid_f.jpg">
                </figure>
            </p>

            <p> Another hybrid image example. The low frequencies in this example are still prominant up close, creating a much more blended-type image up close. </p>

            <figure class="line">
                <img src="data/lazaro.jpg">
                <img src="data/me.jpg">
            </figure>

            

            <figure class="line">
                <img src="data/laz_blur.jpg">
                <img src="data/me_hf.jpg">
                <img src='data/hybrid_melaz.jpg'>
            </figure>

            <p> We can also use color to enhance the effect. The colors from the low frequency image are much more dominant than those in the high frequency image.
                Below, from left to right, we see the high frequency image in color, the low frequency image in color, and finally both in color. The first image 
                has the effect of highlighting the child more from the background. The second and third image appear nearly identical, and give color to the baby's face.
                If the images were overlapping more, perhaps this effect would work to color both images effectively. Here, however, the color of the low frequency image
                is very noticable and distracting up close. Ultimately the most effective blend is the first one.
            </p>

                <figure class="line">
                    <img src="data/babytrump_color1.jpg">
                    <img src="data/babytrump_color2.jpg">
                    <img src="data/babytrump_color3.jpg">
                </figure>
            

            <p><b> 2.3 Gaussian and Laplacian stacks </b> 
                Below we can see the Laplacian stacks used to merge the apple and orange images.
            </p>
            <figure class="line">
                <img src="data/apple1.jpg">
                <img src="data/orange1.jpg">
                <img src='data/hybrid1.jpg'>
            </figure>
            <figure class="line">
                <img src="data/apple2.jpg">
                <img src="data/orange2.jpg">
                <img src='data/hybrid2.jpg'>
            </figure>
            <figure class="line">
                <img src="data/apple3.jpg">
                <img src="data/orange3.jpg">
                <img src='data/hybrid3.jpg'>
            </figure>
            <figure class="line">
                <img src="data/halfapple.jpg">
                <img src="data/halforange.jpg">
                <img src='data/orapple.jpg'>
            </figure>

            <p><b> 2.4 Additional multiresolution blending </b> 
                <figure class="line">
                    <img src="data/pepsi.png">
                    <img src="data/coke.jpeg">
                    <img src='data/cokepepsi.jpg'>
                </figure>

                <figure class="line">
                    <img src="data/dog.jpg">
                    <img src="data/watermelon.jpg">
                    <img src='data/waterdog.jpg'>
                </figure>
            </p>

            <p> <b>Using color to enhance the effect: </b> multiresolution blending makes sense when the color saturation in each image is roughly the same. I have 
            strategically chosen all the previous images to meet this requirement.
            However, if we blend the apple (undersaturated) and the coke (over saturated) as shown below, the effect is less convincing despite red being blended
            with red. Below, using a simple masking technique to dampen the color of the coke can, the resulting blended image is more convincing. While this masking
            technique created other issues with the coke image, the second image below still illustrates how images with similar color channels can blend more effectively.
        
        </p>

            <center>
                <img src ='data/cokeapple.jpg'>
                <img src="data/cokeapple_blur.jpg">
            </center>

            <p> If we instead match the saturations, the image blending is much more convincing. </p>
        </section>
    </div>
  </main>